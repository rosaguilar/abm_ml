{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a2b208-b7c6-44be-9220-b2fb9b000d68",
   "metadata": {},
   "source": [
    "<h2> RF </h2>\n",
    "Trains a Random Forest model to classify stringency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577e77c6-5921-40ef-bc32-a6f01c7a414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mapclassify\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, classification_report\n",
    "\n",
    "from itertools import product\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d075c3b-5fb2-47c7-98dd-b5ce5708f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore a specific warning\n",
    "warnings.filterwarnings('ignore', message='parsing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a77083-4b83-4539-bde1-ea041cb8ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF params\n",
    "\n",
    "random_state = 0\n",
    "min_samples_leaf = 15\n",
    "max_depth = 50\n",
    "n_classes = 3\n",
    "\n",
    "# target y for prediction, e.g., low, medium or very high pollen\n",
    "ytarget = 'stringency_type_int'\n",
    "column = 'stringency'\n",
    "area = 'whole'  # 'nl', 'all'\n",
    "dic_labels = {0: 'low', 1: 'medium', 2: 'high'}\n",
    "dic_labels_inv = {'low': 1, 'medium': 2, 'high': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5a478a-a367-4257-b23a-6b133e06fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_reported</th>\n",
       "      <th>Country</th>\n",
       "      <th>Cases per 100000</th>\n",
       "      <th>Deaths per 100000</th>\n",
       "      <th>ICU per 100000</th>\n",
       "      <th>stringency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>Austria</td>\n",
       "      <td>7,524952338</td>\n",
       "      <td>0,235505215</td>\n",
       "      <td>2,411124818</td>\n",
       "      <td>81,48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>Austria</td>\n",
       "      <td>6,179208254</td>\n",
       "      <td>0,201861613</td>\n",
       "      <td>2,455982954</td>\n",
       "      <td>81,48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>Austria</td>\n",
       "      <td>6,156779186</td>\n",
       "      <td>0,123359874</td>\n",
       "      <td>2,747560839</td>\n",
       "      <td>81,48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>Austria</td>\n",
       "      <td>4,911965908</td>\n",
       "      <td>0,224290681</td>\n",
       "      <td>2,747560839</td>\n",
       "      <td>81,48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>Austria</td>\n",
       "      <td>4,620388023</td>\n",
       "      <td>0,201861613</td>\n",
       "      <td>2,736346305</td>\n",
       "      <td>81,48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5638</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>UK</td>\n",
       "      <td>49,19051878</td>\n",
       "      <td>0,09391771</td>\n",
       "      <td>1,23881932</td>\n",
       "      <td>41,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>UK</td>\n",
       "      <td>55,88103757</td>\n",
       "      <td>0,059630292</td>\n",
       "      <td>1,231365534</td>\n",
       "      <td>41,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>UK</td>\n",
       "      <td>51,46094216</td>\n",
       "      <td>0,24895647</td>\n",
       "      <td>1,211985689</td>\n",
       "      <td>41,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>UK</td>\n",
       "      <td>52,26446035</td>\n",
       "      <td>0,223613596</td>\n",
       "      <td>1,214967203</td>\n",
       "      <td>41,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5642</th>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>UK</td>\n",
       "      <td>53,28264758</td>\n",
       "      <td>0,204233751</td>\n",
       "      <td>1,20005963</td>\n",
       "      <td>41,2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5643 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_reported  Country Cases per 100000 Deaths per 100000 ICU per 100000  \\\n",
       "0       2020-01-04  Austria      7,524952338       0,235505215    2,411124818   \n",
       "1       2020-02-04  Austria      6,179208254       0,201861613    2,455982954   \n",
       "2       2020-03-04  Austria      6,156779186       0,123359874    2,747560839   \n",
       "3       2020-04-04  Austria      4,911965908       0,224290681    2,747560839   \n",
       "4       2020-05-04  Austria      4,620388023       0,201861613    2,736346305   \n",
       "...            ...      ...              ...               ...            ...   \n",
       "5638    2021-09-27       UK      49,19051878        0,09391771     1,23881932   \n",
       "5639    2021-09-28       UK      55,88103757       0,059630292    1,231365534   \n",
       "5640    2021-09-29       UK      51,46094216        0,24895647    1,211985689   \n",
       "5641    2021-09-30       UK      52,26446035       0,223613596    1,214967203   \n",
       "5642    2021-01-10       UK      53,28264758       0,204233751     1,20005963   \n",
       "\n",
       "     stringency  \n",
       "0         81,48  \n",
       "1         81,48  \n",
       "2         81,48  \n",
       "3         81,48  \n",
       "4         81,48  \n",
       "...         ...  \n",
       "5638       41,2  \n",
       "5639       41,2  \n",
       "5640       41,2  \n",
       "5641       41,2  \n",
       "5642       41,2  \n",
       "\n",
       "[5643 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa = pd.read_csv('Training.csv', sep=';', parse_dates=['Date_reported'])\n",
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df01e5f2-d5db-4104-9793-3ed2e8a70f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_reported</th>\n",
       "      <th>Cases per 100000</th>\n",
       "      <th>Deaths per 100000</th>\n",
       "      <th>ICU per 100000</th>\n",
       "      <th>stringency</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0,040137615</td>\n",
       "      <td>5,56</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0,005733945</td>\n",
       "      <td>0</td>\n",
       "      <td>0,04587156</td>\n",
       "      <td>5,56</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0,051605505</td>\n",
       "      <td>5,56</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0,005733945</td>\n",
       "      <td>0</td>\n",
       "      <td>0,063073394</td>\n",
       "      <td>5,56</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>0,017201835</td>\n",
       "      <td>0</td>\n",
       "      <td>0,05733945</td>\n",
       "      <td>5,56</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>9,174311927</td>\n",
       "      <td>0,005733945</td>\n",
       "      <td>0,940366972</td>\n",
       "      <td>41,67</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>7,964449541</td>\n",
       "      <td>0,02293578</td>\n",
       "      <td>0,883027523</td>\n",
       "      <td>41,67</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>9,850917431</td>\n",
       "      <td>0,04587156</td>\n",
       "      <td>0,819954128</td>\n",
       "      <td>41,67</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>10,04587156</td>\n",
       "      <td>0,03440367</td>\n",
       "      <td>0,802752294</td>\n",
       "      <td>41,67</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>9,776376147</td>\n",
       "      <td>0,01146789</td>\n",
       "      <td>0,756880734</td>\n",
       "      <td>41,67</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Date_reported Cases per 100000 Deaths per 100000 ICU per 100000  \\\n",
       "0      2020-02-27                0                 0    0,040137615   \n",
       "1      2020-02-28      0,005733945                 0     0,04587156   \n",
       "2      2020-02-29                0                 0    0,051605505   \n",
       "3      2020-01-03      0,005733945                 0    0,063073394   \n",
       "4      2020-02-03      0,017201835                 0     0,05733945   \n",
       "..            ...              ...               ...            ...   \n",
       "578    2021-09-27      9,174311927       0,005733945    0,940366972   \n",
       "579    2021-09-28      7,964449541        0,02293578    0,883027523   \n",
       "580    2021-09-29      9,850917431        0,04587156    0,819954128   \n",
       "581    2021-09-30      10,04587156        0,03440367    0,802752294   \n",
       "582    2021-01-10      9,776376147        0,01146789    0,756880734   \n",
       "\n",
       "    stringency      Country  \n",
       "0         5,56  Netherlands  \n",
       "1         5,56  Netherlands  \n",
       "2         5,56  Netherlands  \n",
       "3         5,56  Netherlands  \n",
       "4         5,56  Netherlands  \n",
       "..         ...          ...  \n",
       "578      41,67  Netherlands  \n",
       "579      41,67  Netherlands  \n",
       "580      41,67  Netherlands  \n",
       "581      41,67  Netherlands  \n",
       "582      41,67  Netherlands  \n",
       "\n",
       "[583 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_filename = 'Netherlands.csv'\n",
    "df = pd.read_csv(training_filename, sep=';', parse_dates=['Date_reported'])\n",
    "df.columns = 'Date_reported', 'Cases per 100000', 'Deaths per 100000', 'ICU per 100000', 'stringency'\n",
    "df['Country'] = 'Netherlands'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdad04d-8482-4663-8483-89df3f86a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(area):\n",
    "    print('-------------' + area)\n",
    "    training_filename = 'Training.csv'\n",
    "    df = pd.read_csv(training_filename, sep=';', parse_dates=['Date_reported'])\n",
    "    \n",
    "    if (area == 'nl'):\n",
    "        training_filename = 'Netherlands.csv'\n",
    "        df = pd.read_csv(training_filename, sep=';', parse_dates=['Date_reported'])\n",
    "        df.columns = 'Date_reported','Cases per 100000', 'Deaths per 100000', 'ICU per 100000', 'stringency'\n",
    "        df['Country'] = 'Netherlands'\n",
    "    # shape\n",
    "    print(training_filename)\n",
    "    \n",
    "    # checkpoint null values\n",
    "    print(df[column].isna().sum())\n",
    "    \n",
    "    # quick look at the data\n",
    "    # df.tail()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7e6c612-8a60-4b4f-b661-b32b69cc4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df):\n",
    "    \n",
    "    # define the var to scale\n",
    "    var_to_scale = ['Cases per 100000','Deaths per 100000','ICU per 100000']\n",
    "    dtypes = {'Cases per 100000':float,'Deaths per 100000':float,'ICU per 100000':float, ytarget:int}\n",
    "    # define a transformer\n",
    "    minmax_transformer = Pipeline(steps=[('minmax', preprocessing.MinMaxScaler())])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        remainder='passthrough', #passthough features not listed\n",
    "        transformers=[('mm', minmax_transformer, var_to_scale)])\n",
    "    Data = preprocessor.fit_transform(df)\n",
    "    new_names = preprocessor.get_feature_names_out()\n",
    "    original_names = [s.replace('mm__','') for s in new_names ]\n",
    "    original_names = [s.replace('remainder__','') for s in original_names ]\n",
    "    Xscaled = pd.DataFrame(data=Data, columns=original_names)\n",
    "    Xscaled = Xscaled.astype({'Cases per 100000':float, 'Deaths per 100000': float, 'ICU per 100000': float,ytarget: int})\n",
    "    return Xscaled\n",
    "\n",
    "def preprocess_data(df):\n",
    "\n",
    "    # change datatype from string to float\n",
    "    df['stringency'] = df['stringency'].apply(lambda x: float(x.replace(',', '.')))\n",
    "    df['Cases per 100000'] = df['Cases per 100000'].apply(lambda x: float(x.replace(',', '.')))\n",
    "\n",
    "    df['Deaths per 100000'] = df['Deaths per 100000'].apply(lambda x: float(x.replace(',', '.')))\n",
    "\n",
    "    df['ICU per 100000'] = df['ICU per 100000'].apply(lambda x: float(x.replace(',', '.')))\n",
    "    df = df.astype({'Cases per 100000':float, 'Deaths per 100000': float, 'ICU per 100000': float,'stringency': float})\n",
    "\n",
    "    # classify stringency - natural breaks\n",
    "    np.random.seed(7)\n",
    "    breaks = list(np.unique(np.insert(mapclassify.NaturalBreaks(df[column], k=n_classes).bins, 0, 0)))\n",
    "    print(breaks)\n",
    "    df[column + '_type_bin'] = pd.cut(df[column].copy(), bins=breaks, labels=False, include_lowest=True)\n",
    "    df[column + '_type'] = df[column + '_type_bin'].map(dic_labels)\n",
    "    df.drop(columns=[column + '_type_bin'], inplace=True)\n",
    "    \n",
    "    # inv map to\n",
    "    df[ytarget] = df[column + '_type'].map(dic_labels_inv)\n",
    "    \n",
    "    # ensure it is an int\n",
    "    df[ytarget] = df[ytarget].apply(lambda x: int(x))\n",
    "    \n",
    "    # print unique values\n",
    "    print(df[ytarget].unique())\n",
    "\n",
    "    # scale\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    Xscaled = scale_df(df)\n",
    "    \n",
    "    return(Xscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b5b4ba6-d6b1-461d-9e2f-0e5fab892ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_all_nl(dfa, dfnl):\n",
    "    \n",
    "    # The al data will be used for training and the NL for testing\n",
    "    df_train = dfa\n",
    "    y_train = df_train[ytarget].to_numpy().ravel()\n",
    "    df_test = dfnl\n",
    "    y_test = df_test[ytarget].to_numpy().ravel()\n",
    "    print('Number of records for training and test ', df_train.shape[0], df_test.shape[0])\n",
    "\n",
    "    return df_train, y_train, df_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe0adc2-9f01-4387-9bb7-b299a59a2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df):\n",
    "    \n",
    "    # print('dtypes in get_train_test', df.dtypes)\n",
    "    ndays = (df.Date_reported.max() - df.Date_reported.min()).days\n",
    "    ndays_tr = int(0.66*ndays)\n",
    "    \n",
    "    date_limit = df.Date_reported.min() + timedelta(days=ndays_tr)\n",
    "    df_train = df.loc[df.Date_reported <= date_limit].copy(deep=True)\n",
    "    y_train = df_train[ytarget].to_numpy().ravel()\n",
    "\n",
    "    df_test = df.loc[df.Date_reported >  date_limit].copy(deep=True)\n",
    "    y_test = df_test[ytarget].to_numpy().ravel()\n",
    "    \n",
    "    print('Number of records for training and test ', df_train.shape[0], df_test.shape[0])\n",
    "\n",
    "    return df_train, y_train, df_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a640e60-138a-4003-b42f-b7e73a1051dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(Y_true, Y_pred):\n",
    "\n",
    "    balanced_OA = balanced_accuracy_score(Y_true, Y_pred, adjusted=True)\n",
    "    # auc = roc_auc_score(Y_true, Y_pred, average= 'weighted')  - only one class is defined as ytrue (the value of the year)\n",
    "    \n",
    "    # true class will be only one, ypred might be different\n",
    "    pred_class = np.unique(Y_pred)\n",
    "    ytrue_class = np.unique(Y_true)\n",
    "    all_class = list(set(np.concatenate([pred_class, ytrue_class])))\n",
    "    \n",
    "    creport = classification_report(Y_true, Y_pred, target_names = [x for x in dic_labels_inv if (dic_labels_inv[x] in all_class)])\n",
    "\n",
    "    return balanced_OA, creport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0012527-1c88-47f0-8d96-defd36460543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_train,  y_train, X_test, y_test):\n",
    "\n",
    "    # Define the features for classification:\n",
    "\n",
    "    exclude = ['Date_reported', 'Country', 'stringency', 'stringency_type', ytarget]\n",
    "    variables = [x for x in X_train.columns if x not in exclude]\n",
    "    # print(sorted(variables))\n",
    "\n",
    "    # Prepare input data for RF - only get the selected feats\n",
    "    X_train_feats = pd.DataFrame(data = X_train[variables])\n",
    "    X_test_feats = pd.DataFrame(data = X_test[variables])\n",
    "\n",
    "    # checkpoint\n",
    "    print(\"X_train  ########## - y_train  ##########\", X_train_feats.shape, y_train.shape)\n",
    "    # print(\"X_train\", X_train_feats.columns)\n",
    "    print(\"X_test  ##########- y_test  ##########\", X_test_feats.shape, y_test.shape)\n",
    "    # print(\"X test\", X_test_feats.columns)\n",
    "\n",
    "    # define a random forest classifier, predict and get the metrics\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 300, random_state = random_state,\n",
    "                                max_depth = max_depth, min_samples_leaf = min_samples_leaf, n_jobs = -1)\n",
    "\n",
    "    rf_classifier = rf.fit(X_train_feats, y_train)\n",
    "\n",
    "    # get the feature importance\n",
    "    importances = pd.Series(rf_classifier.feature_importances_, index=variables)\n",
    "    \n",
    "    # prediction\n",
    "    yhat_tr = rf_classifier.predict(X_train_feats)\n",
    "    yhat_ts = rf_classifier.predict(X_test_feats)\n",
    "\n",
    "    # compute metrics over Tr and Ts\n",
    "\n",
    "    OA_tr = accuracy_score(y_train, yhat_tr)\n",
    "    OA_ts = accuracy_score(y_test, yhat_ts)\n",
    "    balanced_OA, creport = get_metrics(y_test, yhat_ts)\n",
    "    print (\"RF metrics (validation) RF: OA: {:.2f}, Train_OA: {:.2f}\".format(OA_ts, OA_tr))\n",
    "\n",
    "    # create series\n",
    "    yseries = pd.concat( [pd.Series(data=y_test, name ='ytrue'),pd.Series(data=yhat_ts, name = 'yhat')], axis=1)\n",
    "    \n",
    "    cols= X_test.columns\n",
    "    result = pd.concat( [X_test[cols].reset_index(drop=True), yseries.reset_index(drop=True)], axis=1)  \n",
    "    # print('result', result)\n",
    "    # save prediction/model and importances to a csv file\n",
    "    predict_filename = 'rf_class' + area + '.csv'\n",
    "    model_name = 'rf_class_' +  area + '.pkl'\n",
    "    result.to_csv(predict_filename, index=False)\n",
    "    importances.to_csv('importances_' + area  + '.csv')\n",
    "\n",
    "    # save the model\n",
    "    with open(model_name, 'wb') as model_file:\n",
    "        pickle.dump(rf_classifier, model_file)\n",
    "    print('Done for ' + area)\n",
    "\n",
    "    return OA_ts, OA_tr, creport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f45e62-ec08-4355-aaf7-7d2a3a2e9970",
   "metadata": {},
   "source": [
    "## Execute RF classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a8889d-54ba-49cf-b73b-2c7da2d8189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------all\n",
      "Training.csv\n",
      "0\n",
      "[0.0, 52.78, 70.37, 90.74]\n",
      "[3 2 1]\n",
      "-------------nl\n",
      "Netherlands.csv\n",
      "0\n",
      "[0.0, 48.15, 67.59, 82.41]\n",
      "[1 2 3]\n",
      "Number of records for training and test  5643 583\n",
      "X_train  ########## - y_train  ########## (5643, 3) (5643,)\n",
      "X_test  ##########- y_test  ########## (583, 3) (583,)\n",
      "RF metrics (validation) RF: OA: 0.57, Train_OA: 0.77\n",
      "Done for whole\n",
      ".........done!\n"
     ]
    }
   ],
   "source": [
    "# defining data\n",
    "\n",
    "results = []\n",
    "\n",
    "# run classification with a 1/3 for testing\n",
    "dfa = get_input_data('all')\n",
    "dfta = preprocess_data(dfa)\n",
    "dfnl = get_input_data('nl')\n",
    "dftnl = preprocess_data(dfnl)\n",
    "\n",
    "X_train,  y_train, X_test, y_test = get_train_test_all_nl(dfta, dftnl)\n",
    "\n",
    "OA_ts, OA_tr, creport = rf(X_train,  y_train, X_test, y_test)\n",
    "results.append({ 'OA_ts': OA_ts, 'OA_tr': OA_tr, 'creport': creport})\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(results)\n",
    "metric_output_file = 'metrics_stringency_new.csv'\n",
    "df_results.to_csv(metric_output_file, index=False)\n",
    "\n",
    "print('.........done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42efb3ea-f3ca-491b-8363-334c31c81231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done...\n"
     ]
    }
   ],
   "source": [
    "print(\"done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79055099-faaf-427d-b4cd-ee63136bc5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
